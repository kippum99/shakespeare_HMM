{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "from HMM import unsupervised_HMM\n",
    "from punctuation_dict import get_punctuation_dict\n",
    "from punctuation_generator import get_punc\n",
    "from syllable_dict import get_syllable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a list of words to keep capitalized\n",
    "cap_words = [\"i'll\", 'i', 'o']\n",
    "punc_dict = get_punctuation_dict()\n",
    "\n",
    "def process_word(word):\n",
    "    '''\n",
    "    This function takes as its input a word and returns the processed word by \n",
    "    getting rid of unnecessary punctuations / capitalizations. \n",
    "    ''' \n",
    "    # Exception \"I'll\" - confusion with ill should be manually taken care of\n",
    "    if word == \"I'll\":\n",
    "        return word\n",
    "    \n",
    "    # Convert to lowercase and remove punctuations not part of a word\n",
    "    word = punc_dict[re.sub(r'[^\\w]', '', word.lower())]\n",
    "\n",
    "    # Keep certain words capitalized\n",
    "    if word in cap_words:\n",
    "        word = word.capitalize()\n",
    "        \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rhyme dictionary\n",
    "\n",
    "lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "sonnets = []\n",
    "sonnet = []\n",
    "for line in lines:\n",
    "    if len(line) == 1:\n",
    "        # Only store sonnets with 14 lines\n",
    "        if len(sonnet) == 14:\n",
    "            sonnets.append(sonnet)\n",
    "        sonnet = []\n",
    "        continue\n",
    "    sonnet.append(line)\n",
    "\n",
    "    \n",
    "# This rhyme dictionary is a list of sets, where all the elements in each set rhyme with each other\n",
    "rhyme_dict = []\n",
    "\n",
    "def add_to_rhyme_dict(w1, w2):\n",
    "    '''\n",
    "    This function takes in a pair of rhyming words and adds them to the rhyme dictionary.\n",
    "    '''\n",
    "    # Store the group that one of the words belongs in, if any\n",
    "    stored = None\n",
    "    \n",
    "    for group in rhyme_dict:\n",
    "        if w1 in group:\n",
    "            if not stored:\n",
    "                group.add(w2)\n",
    "                stored = group\n",
    "            else:\n",
    "                # Combine two groups\n",
    "                stored.update(group)\n",
    "                rhyme_dict.remove(group)\n",
    "                break\n",
    "        elif w2 in group:\n",
    "            if not stored:\n",
    "                group.add(w1)\n",
    "                stored = group\n",
    "            else:\n",
    "                # Combine two groups\n",
    "                stored.update(group)\n",
    "                rhyme_dict.remove(group)\n",
    "                break\n",
    "    \n",
    "    if not stored:\n",
    "        rhyme_dict.append({w1, w2})\n",
    "        \n",
    "        \n",
    "for sonnet in sonnets:\n",
    "    # Get all the rhyming pairs in the first 3 stanzas\n",
    "    for i in [0, 1, 4, 5, 8, 9]:\n",
    "        word1 = process_word(sonnet[i][-1])\n",
    "        word2 = process_word(sonnet[i+2][-1])\n",
    "        add_to_rhyme_dict(word1, word2)\n",
    "    # Last two rows of a sonnet rhyme\n",
    "    add_to_rhyme_dict(process_word(sonnet[12][-1]), process_word(sonnet[13][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "    \n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    # Iterate through all the lines of poems\n",
    "    for line in lines:\n",
    "        # Skip line with poem id (not an actual line of poem)\n",
    "        if len(line) == 1:\n",
    "            continue\n",
    "\n",
    "        # Reverse the line to train the HMM on reversed sequences\n",
    "        line.reverse()\n",
    "        \n",
    "        obs_elem = []\n",
    "        \n",
    "        for word in line:\n",
    "            word = process_word(word)\n",
    "            \n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, obs_map = parse_observations(text)\n",
    "syl_dict = get_syllable_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Iteration: 20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "Iteration: 30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "Iteration: 40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "Iteration: 50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "Iteration: 60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "Iteration: 70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "Iteration: 80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "Iteration: 90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "Iteration: 100\n"
     ]
    }
   ],
   "source": [
    "hmm = unsupervised_HMM(obs, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r\n",
    "\n",
    "\n",
    "def sample_sentence_simple(hmm, obs_map, n_syl=10):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "\n",
    "    # Sample and convert sentence.\n",
    "    emission, states = hmm.generate_emission(n_syl, obs_map_r, syl_dict)\n",
    "    sentence = [obs_map_r[i] for i in emission][::-1]\n",
    "    sentence[0] = sentence[0].capitalize()\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "\n",
    "# Generate a sample sentence ending with a given word\n",
    "def sample_sentence(hmm, obs_map, word, n_syl=10):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    \n",
    "    # Choose a state that could have generated the word\n",
    "    state = hmm.find_state(obs_map[word])\n",
    "    \n",
    "    # Sample and convert sentence\n",
    "    emission = hmm.generate_emission_rhyme(n_syl, obs_map, obs_map_r, syl_dict, word, state)[0]\n",
    "    sentence = [obs_map_r[i] for i in emission][::-1]\n",
    "    sentence[0] = sentence[0].capitalize()\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "\n",
    "def generate_rhyming_sentences(hmm, obs_map, n_sentences=2, n_syl=10):\n",
    "    # Choose a rhyming group with enough words\n",
    "    groups = []\n",
    "    for group in rhyme_dict:\n",
    "        if len(group) >= n_sentences:\n",
    "            groups.append(group)\n",
    "    \n",
    "    # Choose rhyming words\n",
    "    words = random.sample(random.choice(groups), n_sentences)\n",
    "    \n",
    "    sentences = []\n",
    "    for word in words:\n",
    "        sentences.append(sample_sentence(hmm, obs_map, word, n_syl))\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "    \n",
    "def generate_sonnet(hmm, obs_map):\n",
    "    poem = ''\n",
    "    for stanza in range(3):\n",
    "        l1, l3 = generate_rhyming_sentences(hmm, obs_map)\n",
    "        l2, l4 = generate_rhyming_sentences(hmm, obs_map)\n",
    "        poem += (l1 + get_punc(0) + '\\n' + l2 + get_punc(0) + '\\n' + \n",
    "                l3 + get_punc(0) + '\\n' + l4 + get_punc(1) + '\\n')\n",
    "        \n",
    "    # Last stanza\n",
    "    l1, l2 = generate_rhyming_sentences(hmm, obs_map)\n",
    "    poem += '  ' + l1 + get_punc(2) + '\\n  ' + l2 + get_punc(3) + '\\n' \n",
    "    print(poem)\n",
    "    \n",
    "\n",
    "def generate_haiku(hmm, obs_map):\n",
    "    print(sample_sentence_simple(hmm, obs_map, 5))\n",
    "    print(sample_sentence_simple(hmm, obs_map, 7))\n",
    "    print(sample_sentence_simple(hmm, obs_map, 5))\n",
    "    \n",
    "    \n",
    "def generate_petrarchan_sonnet(hmm, obs_map):\n",
    "    '''\n",
    "    Generate a Petrarchan sonnet with rhyming scheme: ABBAABBA CDCDCD\n",
    "    '''\n",
    "    poem = ''\n",
    "    \n",
    "    # Generate 2 groups of 4 rhyming sentences (A, B),\n",
    "    # 2 groups of 3 rhyming sentences (C, D)\n",
    "    A = generate_rhyming_sentences(hmm, obs_map, 4)\n",
    "    B = generate_rhyming_sentences(hmm, obs_map, 4)\n",
    "    C = generate_rhyming_sentences(hmm, obs_map, 3)\n",
    "    D = generate_rhyming_sentences(hmm, obs_map, 3)\n",
    "    \n",
    "    # First stanza\n",
    "    poem += (A[0] + '\\n' + B[0] + '\\n' + B[1] + '\\n' + A[1] + '\\n' + \n",
    "            A[2] + '\\n' + B[2] + '\\n' + B[3] + '\\n' + A[3] + '\\n' + '\\n')\n",
    "    \n",
    "    # Second stanza\n",
    "    for i in range(3):\n",
    "        poem += C[i] + '\\n' + D[i] + '\\n'\n",
    "        \n",
    "    print(poem)\n",
    "        \n",
    "\n",
    "def generate_limerick(hmm, obs_map):\n",
    "    '''\n",
    "    Generate a limerick with rhyming scheme: AABBA\n",
    "    '''\n",
    "    # Generate 3 rhyming sentences (A) with n1 syllables,\n",
    "    # 2 rhyming sentences (B) with n2 syllables\n",
    "    \n",
    "    n1 = random.randint(7, 10)\n",
    "    n2 = random.randint(5, 7)\n",
    "    \n",
    "    A = generate_rhyming_sentences(hmm, obs_map, 3, n1)\n",
    "    B = generate_rhyming_sentences(hmm, obs_map, 2, n2)\n",
    "    \n",
    "    print(A[0] + '\\n' + A[1] + '\\n' + B[0] + '\\n' + B[1] + '\\n' + A[2] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My worth she honour or proud the disease\n",
      "Love I not no call beauty's a their used:\n",
      "So so in dead their show then love in please,\n",
      "Winds report the honour thou could abused.\n",
      "My roses hast flies who I you am can,\n",
      "Lack in a store but as proof that shape slave\n",
      "Or verse and his mistress of that the man,\n",
      "Must yet will from him and frailties to crave.\n",
      "It death change withering in the beauties blood,\n",
      "Of it and see those but nor to did chips,\n",
      "The thing for thou my for in thy might brood,\n",
      "Mayst been to of this were love fearing lips!\n",
      "  You whose grave from new and tyrant once purge:\n",
      "  Grounded kingly and their all such hour urge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_sonnet(hmm, obs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thy are to transport\n",
      "If so if check love so though\n",
      "Springs which whether I where\n"
     ]
    }
   ],
   "source": [
    "generate_haiku(hmm, obs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought my colour verse keeps my crests can made\n",
      "She love my desire humble to see tomb\n",
      "Height in like world I knowing strange shall womb\n",
      "Live delight them in more thee think my shade\n",
      "Whence thee is so be no and no shouldst fade\n",
      "My self use lie with compounded of dumb\n",
      "Fortune's for is beauty maladies come\n",
      "Give or kind wherein cruel shows since jade\n",
      "\n",
      "Doth put a perfumed new-fangled impute\n",
      "Is flattered forth contented in from fair\n",
      "Lust the their worst thou them women's stop fruit\n",
      "Past with sweetest name with tiger's repair\n",
      "On but gilded and since loves of lacked mute\n",
      "With are charactered rich join with stage air\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_petrarchan_sonnet(hmm, obs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worth but lose his wealth not foul slide\n",
      "O wherein my which hath belied\n",
      "Thou to your earth be perish\n",
      "Dost prepare my true cherish\n",
      "Beauteous love he make an abide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_limerick(hmm, obs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
